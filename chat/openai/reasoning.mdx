---
title: "推理模型"
description: "使用推理模型（如 o4-mini、DeepSeek）并控制推理深度"
---

# 推理模型

推理模型（Reasoning Models）在回答前会进行深度思考，适合数学、编程、逻辑推理等复杂任务。Crazyrouter 支持多种推理模型，并提供推理深度控制。

## 支持的推理模型

| 模型 | 说明 |
|------|------|
| `o4-mini` | OpenAI 推理模型，平衡速度和能力 |
| `o3` | OpenAI 高级推理模型 |
| `o3-mini` | OpenAI 轻量推理模型 |
| `deepseek-r1` | DeepSeek 推理模型 |
| `deepseek-v3-1` | DeepSeek V3.1 |
| `claude-sonnet-4-20250514` | Claude 支持 extended thinking |
| `gemini-2.5-flash-thinking` | Gemini 思考模型 |

---

## reasoning_effort 参数

通过 `reasoning_effort` 控制模型的推理深度：

| 值 | 说明 |
|------|------|
| `low` | 快速回答，适合简单问题 |
| `medium` | 适度推理，平衡速度和质量 |
| `high` | 深度推理，适合复杂问题 |

<CodeGroup>

```bash cURL
curl https://crazyrouter.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "o4-mini",
    "messages": [
      {"role": "user", "content": "证明根号2是无理数"}
    ],
    "reasoning_effort": "high"
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://crazyrouter.com/v1"
)

response = client.chat.completions.create(
    model="o4-mini",
    messages=[
        {"role": "user", "content": "证明根号2是无理数"}
    ],
    reasoning_effort="high"
)

print(response.choices[0].message.content)
```

```javascript Node.js
import OpenAI from "openai";

const client = new OpenAI({
  apiKey: "YOUR_API_KEY",
  baseURL: "https://crazyrouter.com/v1",
});

const response = await client.chat.completions.create({
  model: "o4-mini",
  messages: [{ role: "user", content: "证明根号2是无理数" }],
  reasoning_effort: "high",
});

console.log(response.choices[0].message.content);
```

</CodeGroup>

---

## thinking 参数（思考预算）

部分模型支持通过 `thinking` 参数精确控制思考 Token 预算：

```python Python
response = client.chat.completions.create(
    model="claude-sonnet-4-20250514",
    messages=[
        {"role": "user", "content": "分析这个算法的时间复杂度并优化"}
    ],
    thinking={
        "type": "enabled",
        "budget_tokens": 10000
    },
    max_tokens=16000
)
```

<Note>
  使用 `thinking` 参数时，`max_tokens` 必须大于 `budget_tokens`，因为 `max_tokens` 包含了思考 Token 和输出 Token。
</Note>

---

## 流式推理

推理模型也支持流式输出。思考过程和最终回答会分别以不同的 chunk 返回：

```python Python
stream = client.chat.completions.create(
    model="o4-mini",
    messages=[
        {"role": "user", "content": "解一个数独题目"}
    ],
    reasoning_effort="medium",
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

---

## DeepSeek 推理模型

DeepSeek 推理模型会在响应中返回思考过程：

```python Python
response = client.chat.completions.create(
    model="deepseek-r1",
    messages=[
        {"role": "user", "content": "9.11和9.8哪个大？"}
    ]
)

# 思考过程可能在 reasoning_content 字段中
message = response.choices[0].message
print("回答:", message.content)
```

<Warning>
  推理模型的 Token 消耗通常远高于普通模型，因为思考过程也会消耗 Token。请注意控制 `reasoning_effort` 和 `budget_tokens` 以管理成本。
</Warning>

<Note>
  推理模型通常不支持 `temperature`、`top_p` 等采样参数。如果传入这些参数，可能会被忽略或返回错误。
</Note>
