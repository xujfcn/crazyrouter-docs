---
title: "创建聊天补全"
description: "使用 POST /v1/chat/completions 端点创建聊天补全，支持流式和非流式响应"
---

# 创建聊天补全

```
POST /v1/chat/completions
```

根据输入的消息列表生成模型回复。支持流式和非流式两种响应模式。

## 认证

在请求头中传入 API Key：

```
Authorization: Bearer YOUR_API_KEY
```

## 请求参数

| 参数 | 类型 | 必填 | 默认值 | 说明 |
|------|------|------|--------|------|
| `model` | string | 是 | - | 模型名称，如 `gpt-4o`、`claude-sonnet-4-20250514`、`gemini-2.5-flash` |
| `messages` | array | 是 | - | 消息列表，每条消息包含 `role` 和 `content` |
| `temperature` | number | 否 | 1 | 采样温度，范围 0-2。值越高输出越随机 |
| `top_p` | number | 否 | 1 | 核采样参数，范围 0-1。与 temperature 二选一使用 |
| `n` | integer | 否 | 1 | 生成的回复数量 |
| `stream` | boolean | 否 | false | 是否启用流式输出 |
| `stream_options` | object | 否 | null | 流式选项。设置 `{"include_usage": true}` 可在最后一个 chunk 中返回用量 |
| `stop` | string\|array | 否 | null | 停止生成的标记，最多 4 个 |
| `max_tokens` | integer | 否 | 模型默认 | 最大生成 Token 数 |
| `presence_penalty` | number | 否 | 0 | 存在惩罚，范围 -2.0 到 2.0 |
| `frequency_penalty` | number | 否 | 0 | 频率惩罚，范围 -2.0 到 2.0 |
| `logprobs` | boolean | 否 | false | 是否返回 logprobs |
| `top_logprobs` | integer | 否 | null | 返回的 top logprobs 数量，0-20 |
| `response_format` | object | 否 | null | 指定输出格式，如 `{"type": "json_object"}` |
| `seed` | integer | 否 | null | 随机种子，用于可复现输出 |
| `tools` | array | 否 | null | 可用工具列表（Function Calling） |
| `tool_choice` | string\|object | 否 | "auto" | 工具选择策略 |
| `user` | string | 否 | null | 终端用户标识 |

### messages 格式

```json
[
  {"role": "system", "content": "你是一个有帮助的助手。"},
  {"role": "user", "content": "你好"},
  {"role": "assistant", "content": "你好！有什么可以帮助你的？"},
  {"role": "user", "content": "介绍一下你自己"}
]
```

支持的 role 值：`system`、`user`、`assistant`、`tool`。

---

## 非流式请求

<CodeGroup>

```bash cURL
curl https://crazyrouter.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      {"role": "system", "content": "你是一个有帮助的助手。"},
      {"role": "user", "content": "用一句话解释什么是人工智能"}
    ],
    "temperature": 0.7
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://crazyrouter.com/v1"
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "你是一个有帮助的助手。"},
        {"role": "user", "content": "用一句话解释什么是人工智能"}
    ],
    temperature=0.7
)

print(response.choices[0].message.content)
```

```javascript Node.js
import OpenAI from "openai";

const client = new OpenAI({
  apiKey: "YOUR_API_KEY",
  baseURL: "https://crazyrouter.com/v1",
});

const response = await client.chat.completions.create({
  model: "gpt-4o",
  messages: [
    { role: "system", content: "你是一个有帮助的助手。" },
    { role: "user", content: "用一句话解释什么是人工智能" },
  ],
  temperature: 0.7,
});

console.log(response.choices[0].message.content);
```

</CodeGroup>

### 非流式响应

```json
{
  "id": "chatcmpl-abc123",
  "object": "chat.completion",
  "created": 1709123456,
  "model": "gpt-4o",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "人工智能是让计算机模拟人类智能行为的技术，使机器能够学习、推理和解决问题。"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 28,
    "completion_tokens": 32,
    "total_tokens": 60
  }
}
```

---

## 流式请求

<CodeGroup>

```bash cURL
curl https://crazyrouter.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      {"role": "system", "content": "你是一个有帮助的助手。"},
      {"role": "user", "content": "用一句话解释什么是人工智能"}
    ],
    "stream": true,
    "stream_options": {"include_usage": true}
  }'
```

```python Python
from openai import OpenAI

client = OpenAI(
    api_key="YOUR_API_KEY",
    base_url="https://crazyrouter.com/v1"
)

stream = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "你是一个有帮助的助手。"},
        {"role": "user", "content": "用一句话解释什么是人工智能"}
    ],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")
```

```javascript Node.js
import OpenAI from "openai";

const client = new OpenAI({
  apiKey: "YOUR_API_KEY",
  baseURL: "https://crazyrouter.com/v1",
});

const stream = await client.chat.completions.create({
  model: "gpt-4o",
  messages: [
    { role: "system", content: "你是一个有帮助的助手。" },
    { role: "user", content: "用一句话解释什么是人工智能" },
  ],
  stream: true,
});

for await (const chunk of stream) {
  const content = chunk.choices[0]?.delta?.content || "";
  process.stdout.write(content);
}
```

</CodeGroup>

### 流式响应

```
data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1709123456,"model":"gpt-4o","choices":[{"index":0,"delta":{"role":"assistant","content":""},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1709123456,"model":"gpt-4o","choices":[{"index":0,"delta":{"content":"人工智能"},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1709123456,"model":"gpt-4o","choices":[{"index":0,"delta":{"content":"是让"},"finish_reason":null}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1709123456,"model":"gpt-4o","choices":[{"index":0,"delta":{},"finish_reason":"stop"}]}

data: {"id":"chatcmpl-abc123","object":"chat.completion.chunk","created":1709123456,"model":"gpt-4o","choices":[],"usage":{"prompt_tokens":28,"completion_tokens":32,"total_tokens":60}}

data: [DONE]
```

<Note>
  设置 `stream_options.include_usage` 为 `true` 后，最后一个 chunk 会包含完整的 `usage` 信息。
</Note>

<Warning>
  `max_tokens` 参数限制的是输出 Token 数，不包括输入。如果输出被截断，`finish_reason` 会返回 `length`。
</Warning>
