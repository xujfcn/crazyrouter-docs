---
title: 'Python Embeddings'
description: 'Python text embedding API usage'
---

## Basic Usage

```python
from openai import OpenAI

client = OpenAI(api_key="sk-xxx", base_url="https://crazyrouter.com/v1")

response = client.embeddings.create(
    model="text-embedding-3-large",
    input="Crazyrouter is an AI model gateway"
)

embedding = response.data[0].embedding
print(f"Dimensions: {len(embedding)}")
```

## Batch Embeddings

```python
texts = [
    "The history of artificial intelligence",
    "Differences between machine learning and deep learning",
    "Applications of natural language processing"
]

response = client.embeddings.create(
    model="text-embedding-3-large",
    input=texts
)

for i, item in enumerate(response.data):
    print(f"Text {i}: dimensions {len(item.embedding)}")
```

## Custom Dimensions

The `text-embedding-3-*` series supports custom output dimensions:

```python
response = client.embeddings.create(
    model="text-embedding-3-large",
    input="Test text",
    dimensions=256  # Reduce to 256 dimensions
)

print(f"Dimensions: {len(response.data[0].embedding)}")  # 256
```

## Compute Similarity

```python
import numpy as np

def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

response = client.embeddings.create(
    model="text-embedding-3-large",
    input=["Cats are pets", "Dogs are also common pets", "Quantum mechanics is a branch of physics"]
)

vectors = [item.embedding for item in response.data]

print(f"Cat vs Dog: {cosine_similarity(vectors[0], vectors[1]):.4f}")
print(f"Cat vs Quantum mechanics: {cosine_similarity(vectors[0], vectors[2]):.4f}")
```

<Note>
  Reducing dimensions can lower storage and computation costs but may sacrifice some accuracy. Test with your specific use case to find the right dimension.
</Note>
